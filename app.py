import streamlit as st
import pandas as pd
import plotly.express as px
import datetime
import json
import urllib.request
import plotly.graph_objects as go
import numpy as np
from sklearn.cluster import DBSCAN  # DBSCAN import'unda gÃ¶rÃ¼nmez karakter hatasÄ± dÃ¼zeltildi

# --- Sayfa YapÄ±landÄ±rmasÄ± ---
st.set_page_config(layout="wide")

# --- Veri YollarÄ± ---
FILE_PATH = r"C:\Users\ASUS\Desktop\TezCalismalar\Earthquakes\Earthquakes_USGS.csv"
GEOJSON_URL = "https://raw.githubusercontent.com/fraxen/tectonicplates/master/GeoJSON/PB2002_boundaries.json"


@st.cache_data
def load_data(file_path):
    """
    CSV dosyasÄ±nÄ± yÃ¼kler, 'time' sÃ¼tununu KARIÅIK formatlarÄ± deneyecek ÅŸekilde
    tarih/saat formatÄ±na Ã§evirir ve sÃ¼tun adlarÄ±nÄ± basitleÅŸtirir.
    """
    try:
        with st.spinner(f"LÃ¼tfen bekleyin... 4.3 Milyon satÄ±rlÄ±k deprem verisi yÃ¼kleniyor..."):
            df = pd.read_csv(file_path)
        
        df.rename(columns={
            'latitude': 'lat',
            'longitude': 'lon',
            'mag': 'magnitude'
        }, inplace=True, errors='ignore')

        with st.spinner("TÃ¼m zaman formatlarÄ± analiz ediliyor... (Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir)"):
            df['time'] = pd.to_datetime(df['time'], format='mixed', errors='coerce', utc=True)

        original_count = len(df)
        df.dropna(subset=['time', 'lat', 'lon', 'magnitude', 'depth'], inplace=True)
        cleaned_count = len(df)
        dropped_count = original_count - cleaned_count
        
        st.success(f"Veri iÅŸleme tamamlandÄ±. Toplam {cleaned_count:,} adet geÃ§erli deprem kaydÄ± yÃ¼klendi.")
        if dropped_count > 0:
            st.warning(f"UYARI: {dropped_count:,} adet satÄ±r, eksik veya bozuk tarih/konum bilgisi nedeniyle atlandÄ±.")
        
        if cleaned_count == 0:
            st.error("HATA: HiÃ§ geÃ§erli veri bulunamadÄ±. CSV dosyanÄ±zÄ±n iÃ§eriÄŸini kontrol edin.")
            return None
            
        return df
        
    except FileNotFoundError:
        st.error(f"HATA: Dosya bulunamadÄ±. LÃ¼tfen '{FILE_PATH}' yolunu kontrol edin.")
        return None
    except Exception as e:
        st.error(f"Veri yÃ¼klenirken bir hata oluÅŸtu: {e}")
        return None

# --- GeoJSON (Tektonik Plaka) YÃ¼kleme Fonksiyonu ---
@st.cache_data
def load_geojson(url):
    """
    Verilen URL'den GeoJSON verisini yÃ¼kler.
    """
    try:
        with st.spinner("Tektonik plaka sÄ±nÄ±rlarÄ± yÃ¼kleniyor..."):
            with urllib.request.urlopen(url) as response:
                geojson_data = json.loads(response.read())
        return geojson_data
    except Exception as e:
        st.error(f"HATA: Tektonik plaka verisi yÃ¼klenemedi: {e}")
        return None

# --- Ana Uygulama BaÅŸlangÄ±cÄ± ---

# Veriyi yÃ¼kle
df = load_data(FILE_PATH)
geojson_data = load_geojson(GEOJSON_URL)

if df is None or geojson_data is None:
    st.stop()

# --- BaÅŸlÄ±k ---
st.title("ğŸŒ GeliÅŸmiÅŸ EtkileÅŸimli Deprem Panosu (1900-2025)")
st.markdown("Bu pano, USGS veri setini kullanarak sismik aktiviteleri, tektonik plakalarÄ±, "
            "enerji salÄ±nÄ±mÄ±nÄ±, frekanslarÄ± ve **Makine Ã–ÄŸrenimi (ML)** ile kÃ¼melenmiÅŸ fay hatlarÄ±nÄ± gÃ¶rselleÅŸtirir.")

# --- KENAR Ã‡UBUÄU (Sidebar) - Filtreler ---
st.sidebar.header("Filtreleme SeÃ§enekleri")

# 1. Tarih AralÄ±ÄŸÄ± Filtresi
st.sidebar.subheader("Tarih AralÄ±ÄŸÄ±")
min_date = df['time'].min().date()
max_date = df['time'].max().date()

st.sidebar.info(f"Veri AralÄ±ÄŸÄ±: **{min_date}** ile **{max_date}** arasÄ±.")

start_date = st.sidebar.date_input("BaÅŸlangÄ±Ã§ Tarihi", min_date, min_value=min_date, max_value=max_date)
end_date = st.sidebar.date_input("BitiÅŸ Tarihi", max_date, min_value=start_date, max_value=max_date)

# 2. BÃ¼yÃ¼klÃ¼k (Magnitude) Filtresi
st.sidebar.subheader("BÃ¼yÃ¼klÃ¼k (Magnitude)")
min_mag = 0.0
max_mag = float(pd.to_numeric(df['magnitude'], errors='coerce').max())

mag_range = st.sidebar.slider(
    "BÃ¼yÃ¼klÃ¼k AralÄ±ÄŸÄ± SeÃ§in",
    min_value=min_mag,
    max_value=max_mag,
    value=(6.5, max_mag),  # BaÅŸlangÄ±Ã§ta 6.5 ve Ã¼zerini gÃ¶ster
    step=0.1
)

# --- YENÄ° EKLEME: 3. Makine Ã–ÄŸrenimi (ML) GÃ¶rÃ¼nÃ¼m SeÃ§eneÄŸi ---
st.sidebar.subheader("Harita GÃ¶rÃ¼nÃ¼mÃ¼ SeÃ§in")
color_by = st.sidebar.radio(
    "Haritadaki noktalarÄ± renklendir:",
    ("BÃ¼yÃ¼klÃ¼k", "Sismik KÃ¼me (DBSCAN)"),
    index=0, # VarsayÄ±lan olarak "BÃ¼yÃ¼klÃ¼k" seÃ§ili gelsin
    help="Sismik KÃ¼me, depremlerin konumlarÄ±na gÃ¶re yoÄŸunlaÅŸtÄ±ÄŸÄ± bÃ¶lgeleri (fay hatlarÄ±nÄ±) "
         "otomatik olarak bulan bir ML modelidir."
)
# --- YENÄ° EKLEME SONU ---


# --- Veriyi Filtreleme ---
start_datetime = pd.to_datetime(start_date, utc=True)
end_datetime = pd.to_datetime(end_date, utc=True) + datetime.timedelta(days=1)

filtered_df = df[
    (df['time'] >= start_datetime) &
    (df['time'] < end_datetime) &
    (pd.to_numeric(df['magnitude'], errors='coerce') >= mag_range[0]) &
    (pd.to_numeric(df['magnitude'], errors='coerce') <= mag_range[1])
]

# --- Performans UyarÄ±sÄ± ---
MAX_POINTS_TO_DISPLAY = 50000
st.sidebar.info(f"Filtre sonucu {len(filtered_df):,} deprem bulundu.")

if len(filtered_df) > MAX_POINTS_TO_DISPLAY:
    st.sidebar.warning(
        f"Ã‡ok fazla sonuÃ§ ({len(filtered_df):,}). TarayÄ±cÄ± performansÄ±nÄ± korumak iÃ§in "
        f"haritada rastgele {MAX_POINTS_TO_DISPLAY:,} nokta gÃ¶steriliyor."
    )
    display_df = filtered_df.sample(MAX_POINTS_TO_DISPLAY)
else:
    display_df = filtered_df.copy() # .copy() ile 'SettingWithCopyWarning' Ã¶nlenir

# --- YÄ±llÄ±k Frekans ve Enerji Analizi iÃ§in Veri HazÄ±rlama ---
if not filtered_df.empty:
    filtered_df['year'] = filtered_df['time'].dt.year
    yearly_counts = filtered_df.groupby('year').size().reset_index(name='count')
    
    analysis_df = filtered_df[['time', 'magnitude']].copy()
    analysis_df['energy'] = np.power(10, 1.5 * pd.to_numeric(analysis_df['magnitude'], errors='coerce'))
    analysis_df = analysis_df.sort_values(by='time')
    analysis_df['cumulative_energy'] = analysis_df['energy'].cumsum()
    
else:
    yearly_counts = pd.DataFrame(columns=['year', 'count'])
    analysis_df = pd.DataFrame(columns=['time', 'cumulative_energy'])


# --- YENÄ° EKLEME: DBSCAN KÃ¼meleme HesaplamasÄ± ---
if color_by == "Sismik KÃ¼me (DBSCAN)" and not display_df.empty:
    with st.spinner("Makine Ã¶ÄŸrenimi modeli (DBSCAN) Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor... YoÄŸun sismik bÃ¶lgeler hesaplanÄ±yor..."):
        # 1. Veriyi hazÄ±rla: DBSCAN, Haversine metriÄŸi iÃ§in radyan bekler
        coords = np.radians(display_df[['lat', 'lon']].values)
        
        # 2. Modeli ayarla
        # eps = 0.03 (Radyan cinsinden. YaklaÅŸÄ±k 190km'lik bir yarÄ±Ã§ap)
        # min_samples = 25 (Bir bÃ¶lgeyi "yoÄŸun" kabul etmek iÃ§in min. deprem sayÄ±sÄ±)
        db = DBSCAN(eps=0.03, min_samples=25, metric='haversine', n_jobs=-1)
        
        # 3. Modeli Ã§alÄ±ÅŸtÄ±r ve kÃ¼meleri al
        clusters = db.fit_predict(coords)
        
        # 4. KÃ¼meleri 'display_df'ye ekle (Plotly iÃ§in string'e Ã§evir)
        # -1 = GÃ¼rÃ¼ltÃ¼ (Noise) olarak etiketlenir
        display_df['cluster'] = [f"KÃ¼me {c}" if c != -1 else "GÃ¼rÃ¼ltÃ¼ (Noise)" for c in clusters]
        
        num_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)
        st.sidebar.success(f"ML modeli {num_clusters} adet ana sismik kÃ¼me buldu.")

elif 'cluster' in display_df.columns:
    # EÄŸer kullanÄ±cÄ± BÃ¼yÃ¼klÃ¼k'e geri dÃ¶nerse, eski sÃ¼tunu temizle
    display_df = display_df.drop(columns=['cluster'])
# --- YENÄ° EKLEME SONU ---


# --- Ana Panel (Dashboard) - GÃ¶rselleÅŸtirmeler ---

st.header("CoÄŸrafi DaÄŸÄ±lÄ±m Analizi")
tab1, tab2 = st.tabs(["Deprem DaÄŸÄ±lÄ±m HaritasÄ± (Scatter Plot)", "Deprem YoÄŸunluk HaritasÄ± (Heatmap)"])

with tab1:
    # --- GÃœNCELLENDÄ°: Harita baÅŸlÄ±ÄŸÄ± ve Ã§izimi artÄ±k ML seÃ§eneÄŸine duyarlÄ± ---
    if color_by == "Sismik KÃ¼me (DBSCAN)":
        st.subheader("Makine Ã–ÄŸrenimi ile Sismik KÃ¼meleme (DBSCAN)")
        st.markdown("Noktalar, ML modelinin bulduÄŸu **Sismik KÃ¼melere** gÃ¶re renklendirilmiÅŸtir. "
                    "Tektonik plakalarÄ± bilmeden bile ana deprem kuÅŸaklarÄ±nÄ± (AteÅŸ Ã‡emberi vb.) gÃ¶rebilirsiniz.")
    else:
        st.subheader("Deprem DaÄŸÄ±lÄ±mÄ± ve Tektonik Plakalar")
        st.markdown("NoktalarÄ±n **rengi ve boyutu** depremin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ile orantÄ±lÄ±dÄ±r. "
                    "**KÄ±rmÄ±zÄ± Ã§izgiler** ana tektonik plaka sÄ±nÄ±rlarÄ±nÄ± gÃ¶sterir.")
    # --- GÃœNCELLEME SONU ---
    
    if not display_df.empty:
        
        # --- GÃœNCELLENDÄ°: Hangi renklendirmeyi kullanacaÄŸÄ±mÄ±za karar ver ---
        if color_by == "Sismik KÃ¼me (DBSCAN)" and 'cluster' in display_df.columns:
            fig_scatter = px.scatter_geo(
                display_df,
                lat='lat',
                lon='lon',
                color='cluster',        # Renklendirme kÃ¼melere gÃ¶re
                hover_name='place',      
                hover_data={'lat': ':.2f', 'lon': ':.2f', 'depth': ':.1f km', 'magnitude': ':.1f'},
                projection="natural earth", 
                title=f"Sismik KÃ¼meler ({start_date.year} - {end_date.year})",
                color_discrete_sequence=px.colors.qualitative.Vivid # AyrÄ± kÃ¼meler iÃ§in belirgin renkler
            )
        else: # VarsayÄ±lan: BÃ¼yÃ¼klÃ¼ÄŸe gÃ¶re
            fig_scatter = px.scatter_geo(
                display_df,
                lat='lat',
                lon='lon',
                color='magnitude',       # Renklendirme bÃ¼yÃ¼klÃ¼ÄŸe gÃ¶re
                size='magnitude',        # BoyutlandÄ±rma bÃ¼yÃ¼klÃ¼ÄŸe gÃ¶re
                hover_name='place',      
                hover_data={           
                    'lat': ':.2f',
                    'lon': ':.2f',
                    'depth': ':.1f km',
                    'time': True,
                    'magnitude': ':.1f'
                },
                projection="natural earth", 
                title=f"Deprem DaÄŸÄ±lÄ±mÄ± ({start_date.year} - {end_date.year})",
                color_continuous_scale=px.colors.sequential.OrRd 
            )
        # --- GÃœNCELLEME SONU ---
        
        # Plaka SÄ±nÄ±rlarÄ±nÄ± Ekleme (Bu kod her iki harita iÃ§in de ortak)
        for feature in geojson_data['features']:
            coords = feature['geometry']['coordinates']
            lons, lats = zip(*coords)
            fig_scatter.add_trace(
                go.Scattergeo(
                    lon = lons,
                    lat = lats,
                    mode = 'lines',
                    line = dict(color='red', width=2),
                    name = 'Plaka SÄ±nÄ±rÄ±',
                    showlegend = False  # <--- 1. DÃœZELTME BURADA
                )
            )
        
        # --- 2. DÃœZELTME BURADA ---
        # Efsaneyi sadece ML KÃ¼meleme gÃ¶rÃ¼nÃ¼mÃ¼ndeyken gÃ¶ster
        show_legend_for_clusters = (color_by == "Sismik KÃ¼me (DBSCAN)")
        fig_scatter.update_layout(height=600, margin={"r":0,"t":40,"l":0,"b":0}, showlegend=show_legend_for_clusters) 
        # --- DÃœZELTME SONU ---
        
        st.plotly_chart(fig_scatter, use_container_width=True)
    else:
        st.warning("Bu filtre kriterlerine uyan veri bulunamadÄ±.")


with tab2:
    st.subheader("Deprem YoÄŸunluk HaritasÄ± (Heatmap) ve Tektonik Plakalar")
    st.markdown("Bu harita, depremlerin coÄŸrafi yoÄŸunluÄŸunu gÃ¶sterir. 'AteÅŸ Ã‡emberi' **kÄ±rmÄ±zÄ± plaka sÄ±nÄ±rlarÄ±** ile Ã§ok daha net gÃ¶rÃ¼lebilir.")

    if not display_df.empty:
        fig_heatmap = px.density_mapbox(
            display_df,
            lat='lat',
            lon='lon',
            z='magnitude',           
            radius=10,               
            center=dict(lat=0, lon=180), 
            zoom=0.5,
            mapbox_style="carto-positron", 
            title=f"Deprem YoÄŸunluk HaritasÄ± ({start_date.year} - {end_date.year})"
        )
        
        # Plaka SÄ±nÄ±rlarÄ±nÄ± Mapbox HaritasÄ±na Ekleme
        fig_heatmap.update_layout(
            mapbox_layers=[
                {
                    "source": geojson_data,
                    "type": "line",
                    "color": "red",
                    "line": {"width": 2}
                }
            ]
        )
        
        fig_heatmap.update_layout(height=600, margin={"r":0,"t":40,"l":0,"b":0})
        st.plotly_chart(fig_heatmap, use_container_width=True)
    else:
        st.warning("Bu filtre kriterlerine uyan veri bulunamadÄ±.")


# --- KÃ¼mÃ¼latif Enerji GrafiÄŸi ---
st.header("KÃ¼mÃ¼latif Sismik Enerji SalÄ±nÄ±mÄ± (Benioff Strain)")
st.markdown("SeÃ§tiÄŸiniz filtreye gÃ¶re zaman iÃ§inde salÄ±nan *toplam* sismik enerjinin birikimi. "
            "Grafikteki dik sÄ±Ã§ramalar, bÃ¼yÃ¼k depremleri temsil eder.")

if not analysis_df.empty:
    fig_energy = px.line(
        analysis_df, 
        x='time', 
        y='cumulative_energy', 
        title="Zaman Ä°Ã§inde KÃ¼mÃ¼latif Enerji SalÄ±nÄ±mÄ±",
        labels={'time': 'Tarih', 'cumulative_energy': 'GÃ¶receli KÃ¼mÃ¼latif Enerji'} 
    )
    fig_energy.update_layout(xaxis_title="Tarih", yaxis_title="GÃ¶receli Toplam Enerji")
    st.plotly_chart(fig_energy, use_container_width=True)
else:
    st.warning("Enerji analizi iÃ§in bu filtre kriterlerine uyan veri bulunamadÄ±.")


# --- YÄ±llÄ±k Frekans GrafiÄŸi ---
st.header("YÄ±llÄ±k Deprem Frekans Analizi")
st.markdown("SeÃ§tiÄŸiniz filtrelere uyan depremlerin yÄ±llara gÃ¶re daÄŸÄ±lÄ±mÄ±.")

if not yearly_counts.empty:
    fig_bar = px.bar(
        yearly_counts, 
        x='year', 
        y='count', 
        title="YÄ±llara GÃ¶re Deprem SayÄ±sÄ±",
        labels={'year': 'YÄ±l', 'count': 'Deprem SayÄ±sÄ±'} 
    )
    fig_bar.update_layout(xaxis_title="YÄ±l", yaxis_title="Toplam Deprem SayÄ±sÄ±")
    st.plotly_chart(fig_bar, use_container_width=True)
else:
    st.warning("YÄ±llÄ±k analiz iÃ§in bu filtre kriterlerine uyan veri bulunamadÄ±.")


# --- Veri Tablosu ---
st.header("FiltrelenmiÅŸ Ham Veri (Ä°lk 1000 satÄ±r)")
# Analiz iÃ§in eklediÄŸimiz sÃ¼tunlarÄ± son tabloda gÃ¶stermeye gerek yok
columns_to_drop = ['year']
if 'cluster' in filtered_df.columns:
    columns_to_drop.append('cluster')
if 'year' in filtered_df.columns:
    st.dataframe(filtered_df.drop(columns=columns_to_drop, errors='ignore').head(1000))
else:
     st.dataframe(filtered_df.head(1000))

